{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl_yJLL8cjqL",
        "outputId": "e4acbd5e-250b-45cd-c67b-e09210fe3476"
      },
      "outputs": [],
      "source": [
        "!pip install networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fjWQuk6_eScZ"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import operator\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "import platform\n",
        "from pandas._libs import parsers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "ReAokHxzeVig",
        "outputId": "465220cc-66d1-4d52-e5cd-57340bc5e269"
      },
      "outputs": [],
      "source": [
        "def import_csv(path, name):\n",
        "    raw = pd.read_csv('{0}{1}.csv'.format(path, name), encoding='utf-8-sig')\n",
        "    df = raw.dropna()\n",
        "    df.head()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9ZhX2LH_c44j"
      },
      "outputs": [],
      "source": [
        "# 리스트가 문자열로 저장된 경우 (ex> [\"['dd','aa']\"])\n",
        "def word_ast(df): \n",
        "  word_list = []\n",
        "\n",
        "  for i in df['Tokens']:\n",
        "    i = ast.literal_eval(i)\n",
        "    word_list.append(i)\n",
        "  print(word_list)\n",
        "  return word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bDRBq2fyfASY"
      },
      "outputs": [],
      "source": [
        "stopwords = ['르', '과', '까지', '곳', '다시금', '제현', '귀엽다', '과', '게', '때','쿠','스트라빈스키','존','사분','김현정','머지않아','팅팅','흑흑','조속히','새끼','미친년','미친놈','개새끼',\n",
        "             '링','보다','경우','반면','되다','있다','자나','살다','혹시','경우','때문','정도','사항','세진','보라','다세','건희','윤호','이재명',\n",
        "                   '해당','겁니다','이것','저것','그것','돋움','신명', '태명', '이미', '돋움','같이','우짜다','어떡하다','제대로',\n",
        "                   '동안','거기','저기','여기','대부분','누구','무엇','고딕','만큼','굴림','감사','건지','텐데',\n",
        "                   '안녕','그렇다','이번','걸로','수고','겁니까','그간','그건','그때','글쓴이','누가','니다','다면','쪼르르','세계인',\n",
        "                   '뭔가','또한','하다','이다','되다','다능','자다','자체','서체','지나가다','잇다','같다','미치','있다','없다', '여지','관련',\n",
        "                   '생각', '현재', '진행', '사람', '마음', '남산', '내용', '현실','음','막','전하다','들다','열다',\n",
        "                   '두다','서다','산하','지금','주변','대상','부분','요즘','하루','마련','시간','이상','행위','고검','야마다','검찰','하루하루','우우','엄밀히','순전히','토니오','술술','몹시','영수','이전',\n",
        "                   '이하','바로 가기','바로가기','제가','먹다','보이다','지나다','콜론','각','대하다','따르다','인하다','전','후','예','한','다','보다','그렇다','좋다',\n",
        "                   '나다','너무','정말','내다','많다','그리다','물론','조금','다시','느끼다','없이','특히','여러','다른','이런','가지다','어떻다','통하다', '위하다','그러다','위하다',\n",
        "                   '다니다','나서다','들다','열다','어떻게','막상','가다','오다','말다','계속','쉬다','혜량','인디','망개','제법','세기',\n",
        "                   '무현','여쭈다','베타','되묻다','뜨다', '다녀오다','서녀','붙다','찾다','생각나다','앉다','바니','이르다','크다',\n",
        "                   '그냥','그저','바로','시키다','허다','내내','해량','걸다', '이렇다','이렇게','켜다','어린이날','그날','남주','제일','지금껏',\n",
        "             '진짜','끌다','받다','넣다','무지','태주','아무튼','알다','틀다','마치','부리','익히다','만들다','잡다','아주','영재','대구','서울','매우','나오다',\n",
        "             '뫄다','케이','히나','이치','경허','비다','찌다','받다','나가다','일어나다','오키','일단','우왕','드리다','큰애',\n",
        "             '대다','덮다','바잔','스다','들어가다','놓아두다','놓다','틀다','들다','사다','팔다','이대로','서교동','조지','치다','그다음','다음',\n",
        "             '마티','파주시','태평','잘나다','모르다','알다','알고있다','주전','작대기','아이스','들뜨다','푸다','아우','쿠쿠','가장','몰다','뭐하다', '눕다', '누르다','하하','냅다',\n",
        "             '존나','데리다','트다','쓰다','타임','라인','벌리다','타다','이제','위하다','다니다','한동안','저번','마이','어쩌다','사실','그렇게','이렇게',\n",
        "             '해보다','해저','가세','시마','블루','부르다','야지', '아무래도', '맞다','파주','동해','랜드','스타','검찰','가요','형질','우현',\n",
        "             '과연','연하다','남자친구','한번','끌어들이다','이날','코난','전혀','최소한','그나저나','레알','님프','테너',\n",
        "             '연월일','동시','문인','민사','당부','모습','바라보다','경애','총비서','동지','모읍','군호','개키다','양치식물','불쑥불쑥','드래건','논란거리','나나미','버크','애니','갑바','요지경','힐러','임화','실로',\n",
        "             '들리다','리츠','달랑달랑','갈수록','크윽','겟다','이따가','프리','오리','두둥실','한마음','분뇨','조다','뽀짝','하마터면','밀다','카다','한쪽','낙도','자기','아장거리다','주도','출처','현이',\n",
        "             '우현','우현이','꿈꾸다','순간','갑자기','히다','분명','중생', '근데','레즈','드르르','집어넣다',\n",
        "             '보통','심의','결정','이유','근처','평점','리뷰','세븐틴','제페','니즈','멜론','혹시나','대충','순응','종종','많이','외려','얼마나','이리저리','돌리다','시간부','곁들이다',\n",
        "             '부풀다','금의환향','하인','의원','위장','광인','제외','바이','고인','고래','모험','스트','레스','왠지','매번','나타나다',\n",
        "             '아오키','가자','데다','어린이','나눠주다','개업','괜히','나머지','최선','이것저것','바라다','바다','다가가다','가시다','최인섭','쓰이다','사리탑','엘리엇',\n",
        "             '사라','정작','얘기','발전','얼마','공산당','일수','만나다','감싸다','누르다','그제서야','태용이','유투','현진','아마','가만히','그린란드','요하다','황두','맘대로','이후','착실히','난초','저렇게','이렇게',\n",
        "             '트로','옛날이야기','온종일','왕비','웃어른', '장모','지폐','진실로','촛불','통역','가스','라이팅','르네','집어넣다','드르르르','르네',\n",
        "             '표시','구라','진실로','저울','어쨌든','난무','어영부영','하하','르네', '냅다','와중','피카','깨닫다','디다','너와', '김선호', '황두', '김래원','연초', '오가타','금상첨화','가을비','손안','하나',\n",
        "             '새끼','잡거','베리','딜리','갈래','진짜로','날아오다','날아가다','인가','역시','갯마을','차차차','두식','주술','회전','시발','아안','하도','왜냐하면','타츠미','루씨','메루','시안','젤로',\n",
        "             '잠시만','아직','비바','응수','강동원','로드','데이브','기실','일주','하여튼','컴백','디비','며칠','졸리','라리','섹트','청주','어서','요시','점심때','이따','가치','새끼','여하튼','너도나도',\n",
        "             '레알','마타','에그','바자','지랄','리사','저벅저벅','아까','서화','시방','사모','나다니다','호시','아월','팔룡','슬쩍','슬그머니','퀴어','위터','포커','조슈야','가요','승관','디노','만납다','꾸리',\n",
        "             '에스','쿱스','맛나','드디어','굳이','이제껏','이리','이제서야','혁이','현아','이따','비록','설마','자꾸','호주','어느새','언제','에리히','화중','업태','에이치','박박','오가타','모토','반드시',\n",
        "             '민규','가령','언제','졸라','레트','리버','이쁜이','재영','트라이','김혜은','다우지','스톤','그리니치','김균','플레','지니','민수','버블','원우','입면','라라','선생','부천','현진이','근년','그룹웨어','시방',\n",
        "             '사바','기철','위즈','파크','한곳','들어오다','기승','강남구','개포동','논현동','임대','개원','어젯밤','거상','베리','라덴','무조건','닷새','국극','개다','세내다','냉큼','브리','루트','한몫',\n",
        "             '오자','엠피','스리','날로','러스','하마','시어터','트리','솔직히','제발','세상','대뜸','혹은','어쩌면','엄청','아무것','모에','사마','부리다','갈다','브이','로그','갖다','묻히다','에디','추스르다','뚝딱','옛날',\n",
        "             '수없이','아직','테라','안네','스톱','최진욱','루프','쏘다','서불','지현','캐시','그대로','라프','또는','내면','이제서야','여전히','한인','성우','레이','위풍당당','범이','임영웅','대체','도저히','구구구',\n",
        "             '논현동','매트','자파','쥐불놀이','심지어','돌아오다','낟다','시발','얼떨결','후욱','양재','충주','복합','로컬','타일','수수','최고','아직','아까','기하다','치가','그럭적럭','하필','주기','난생처음','여태','대체',\n",
        "             '엮다','짓다','주무','세요','엉엉','살짝','넘다','요부','어찌나','어쩌다','무려','앞날','놔주다','고야','굉장히','선천','앞쪽','가리다','아래','결국','의하다','삼성리']\n",
        "#stopwords_set = set(stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVfz4yFrjVRG",
        "outputId": "38af590b-8c59-4c5c-c252-b468a012d5c2"
      },
      "outputs": [],
      "source": [
        "def count_csv_export(path, name_count):\n",
        "    # 빈도수 기준으로 단어 제거 위함(트위터_자연어처리_함수.ipynb 에서 만든 워드카운트 파일 기준)\n",
        "    count = pd.read_csv('{0}{1}_count.csv'.format(path, name_count), encoding='cp949')\n",
        "    count.head()\n",
        "    # count.dtypes\n",
        "    count = count[count['count'] >= 15] # 빈도수 40개 이상\n",
        "    count_list = list(count['tag'])\n",
        "    print('리스트 총 개수 :', len(count_list))\n",
        "    return count_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vhHSbnZKjvBC"
      },
      "outputs": [],
      "source": [
        "def cleard_def(word_list, count_list):\n",
        "    cleared_list = []\n",
        "    li_1 = []\n",
        "    li_2 = []\n",
        "    list1 = []\n",
        "\n",
        "    # 불용어(stopwords)에 해당하는 요소 제외 -> list1\n",
        "    for word in word_list:\n",
        "        li_1 = []\n",
        "        for w in word:\n",
        "            if w not in stopwords:\n",
        "                li_1.append(w)\n",
        "        list1.append(li_1)\n",
        "\n",
        "    # 빈도수 기준(count_list) 충족하는 요소 추출 -> cleared_list\n",
        "    for li in list1:\n",
        "        li_2 = []\n",
        "        for l in li:\n",
        "            if l in count_list:\n",
        "                li_2.append(l)\n",
        "        cleared_list.append(li_2)\n",
        "    # print(cleared_list[:5])\n",
        "    return cleared_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RkbvkDxD3S3",
        "outputId": "357d649c-395a-451c-bbc8-e973b6bcc3d4"
      },
      "outputs": [],
      "source": [
        "# 추가 단어가 필요할 때 단어 추가하기\n",
        "def cleared_def2(cleared_list):\n",
        "  cleared_list2=[]\n",
        "  for cleared in cleared_list:\n",
        "    #cleared : [ ]\n",
        "    cnt = cleared.count('편평')\n",
        "    print('전 :', cleared)\n",
        "    li_3 = []\n",
        "    #c : 한 리스트 안 요소들\n",
        "    idx = 0  \n",
        "    for c in cleared:\n",
        "      if c not in ['편평','태선']:\n",
        "        li_3.append(c)\n",
        "        idx += 1\n",
        "\n",
        "      elif c == '편평':\n",
        "        li_3.insert(idx,'구강편평태선')\n",
        "        idx += 1\n",
        "      \n",
        "      elif c == '태선':\n",
        "        pass\n",
        "      \n",
        "    cleared_list2.append(li_3)        \n",
        "    print('후 :', li_3,'\\n')\n",
        "\n",
        "    cleared_list = cleared_list2\n",
        "  return cleared_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qfYGqUd4ju7d"
      },
      "outputs": [],
      "source": [
        "def export_network(df, cleared_list, path, name):\n",
        "    # 기존 데이터프레임에 새로운 row 추가\n",
        "    df['cleared_token'] = cleared_list\n",
        "    df.head()\n",
        "    df.to_csv('{0}{1}_네트워크.csv'.format(path, name), encoding ='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG4aw0kaj6YT"
      },
      "source": [
        "### 동시 출현 빈도 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IxaV-wHgju11"
      },
      "outputs": [],
      "source": [
        "def co_occurrence(word_list):\n",
        "    # 동시 출현 빈도\n",
        "    count = {}\n",
        "\n",
        "    for context in word_list:\n",
        "        #print(context)\n",
        "        for i, a in enumerate(context):\n",
        "            for b in context[i+1:]:\n",
        "                if a>b:\n",
        "                    count[b,a] = count.get((b,a),0) + 1\n",
        "                else:\n",
        "                    count[a,b] = count.get((a,b),0) + 1\n",
        "\n",
        "    count = {key: value for key, value in count.items() if key[0] != key[1]}\n",
        "    count\n",
        "    return count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gy6lqCjievl"
      },
      "source": [
        "### 메트릭스 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FaMgo7c-idPP"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import ConditionalFreqDist\n",
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nFae0X3XidTj"
      },
      "outputs": [],
      "source": [
        "# 단어 제거한 파일 저장 후에 한번더 불러와야 코드 정상작동함 (전처리 부분에 저장코드 있음)\n",
        "def network_import(path, name_network):\n",
        "    df = pd.read_csv('{0}{1}_완료_네트워크.csv'.format(path, name_network), encoding='utf-8-sig')\n",
        "    df['cleared_token']\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlqvFPEBidbt",
        "outputId": "338d209b-c163-4818-e538-f71d76c152f6"
      },
      "outputs": [],
      "source": [
        "# 빈문자열 확인 코드\n",
        "def empty_string(df):\n",
        "  \n",
        "  words = []\n",
        "  bigram = []\n",
        "  token =[]\n",
        "\n",
        "  # 빈 리스트 제거 후에 처리 시작(안하면 token += 부분에서 오류)\n",
        "  df = df.replace('[]',np.nan)\n",
        "  df = df.dropna(how = 'any')\n",
        "\n",
        "  for i in df['cleared_token']:\n",
        "      #print(i)\n",
        "      i = ast.literal_eval(i)\n",
        "      words.append(i)\n",
        "\n",
        "  # # 단어 두 개씩 조합\n",
        "  for word in words:\n",
        "      #print(word)\n",
        "      bigrams = ngrams(word, 2)\n",
        "      bigram.append(bigrams)\n",
        "\n",
        "  for i in bigram:\n",
        "    token += ([x for x in i])\n",
        "\n",
        "  cfd = ConditionalFreqDist(token)\n",
        "  cfd.conditions()\n",
        "  print('토큰의 총 개수 :', len(token))\n",
        "  \n",
        "  # 메트릭스 만들기\n",
        "  freq_matrix = []\n",
        "\n",
        "  for i in cfd.keys():\n",
        "    temp = []\n",
        "    for j in cfd.keys():\n",
        "      temp.append(cfd[i][j])\n",
        "    freq_matrix.append(temp)\n",
        "  freq_matrix = np.array(freq_matrix)\n",
        "\n",
        "  df = pd.DataFrame(freq_matrix, index = cfd.keys(), columns = cfd.keys())\n",
        "  # df.style.background_gradient(cmap='coolwarm')\n",
        "  # df.head()\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XNR1eji_iz-Z"
      },
      "outputs": [],
      "source": [
        "def final_csv_export(df, path, name_matrix):\n",
        "    df.to_csv('{0}{1}_matrix.csv'.format(path, name_matrix), encoding ='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # klist = ['구내염', '시린이', '잇몸영양제', '잇몸치료', '충치', '치과', '치과비용', '치아교정', '치아미백', '치주염']\n",
        "    # klist = ['1분기', '2분기', '3분기', '4분기']\n",
        "   \n",
        "    path = 'C:/Users/User/Desktop/fproject/캠핑/2018/결과_data/'\n",
        "    # path = 'C:/Users/User/Desktop/fproject/캠핑/2021/월_결과_data/'\n",
        "\n",
        "    # for i in klist:\n",
        "    #     name = f'캠핑2021_{i}_완료'\n",
        "    #     df = import_csv(path, name)\n",
        "    #     word_list = word_ast(df)\n",
        "        \n",
        "    #     name_count = f'캠핑2021_{i}'\n",
        "    #     count_list = count_csv_export(path, name_count)\n",
        "    #     cleared_list = cleard_def(word_list, count_list)\n",
        "    #     # cleared_list = cleared_def2(cleared_list)\n",
        "        \n",
        "    #     export_network(df, cleared_list, path, name)\n",
        "    \n",
        "    # for i in range(1, 13):\n",
        "    #     name = f'캠핑2021_{i}월_완료'\n",
        "    #     df = import_csv(path, name)\n",
        "    #     word_list = word_ast(df)\n",
        "        \n",
        "    #     name_count = f'캠핑2021_{i}월'\n",
        "    #     count_list = count_csv_export(path, name_count)\n",
        "    #     cleared_list = cleard_def(word_list, count_list)\n",
        "    #     # cleared_list = cleared_def2(cleared_list)\n",
        "        \n",
        "    #     export_network(df, cleared_list, path, name)\n",
        "\n",
        "    name = '캠핑2018_완료'\n",
        "    df = import_csv(path, name)\n",
        "    word_list = word_ast(df)\n",
        "\n",
        "    name_count = '캠핑2018'\n",
        "    count_list = count_csv_export(path, name_count)\n",
        "    cleared_list = cleard_def(word_list, count_list)\n",
        "    # cleared_list = cleared_def2(cleared_list)\n",
        "\n",
        "    export_network(df, cleared_list, path, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "토큰의 총 개수 : 1416\n"
          ]
        }
      ],
      "source": [
        "# 메트리스 만들기\n",
        "# klist = ['구내염', '시린이', '잇몸영양제', '잇몸치료', '충치', '치과', '치과비용', '치아교정', '치아미백', '치주염']\n",
        "# klist = ['1분기', '2분기', '3분기', '4분기']\n",
        "\n",
        "path = 'C:/Users/User/Desktop/fproject/캠핑/2018/결과_data/'\n",
        "# path = 'C:/Users/User/Desktop/fproject/캠핑/2021/월_결과_data/'\n",
        "\n",
        "# for i in klist:\n",
        "#     name_network = f'캠핑2021_{i}'\n",
        "#     df = network_import(path, name_network)\n",
        "#     df = empty_string(df)\n",
        "#     name_matrix = f'캠핑2021_{i}' \n",
        "#     final_csv_export(df, path, name_matrix)\n",
        "\n",
        "# for i in range(1, 13):\n",
        "#     name_network = f'캠핑2021_{i}월'\n",
        "#     df = network_import(path, name_network)\n",
        "#     df = empty_string(df)\n",
        "#     name_matrix = f'캠핑2021_{i}월' \n",
        "#     final_csv_export(df, path, name_matrix)\n",
        "\n",
        "name_network = f'캠핑2018'\n",
        "df = network_import(path, name_network)\n",
        "df = empty_string(df)\n",
        "name_matrix = f'캠핑2018' \n",
        "final_csv_export(df, path, name_matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "메크릭스.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
